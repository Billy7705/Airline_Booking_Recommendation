{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44736a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.autograd as autograd \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d33dfe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>context_feature_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>28366</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>16109</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>11500</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>20750</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>8759</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  context_feature_id\n",
       "0        0    28366                   2\n",
       "1        0    16109                   2\n",
       "2        0    11500                   3\n",
       "3        0    20750                   2\n",
       "4        0     8759                   2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('training.csv')\n",
    "items_features = pd.read_csv('item_feature.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51d14b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab915451",
   "metadata": {},
   "source": [
    "# Zero Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd608b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['feedback'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ce39e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(970245, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145d639a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3462f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_sampling(df_, users_list, item_list, context_list, all_users = False, all_items = False):\n",
    "    N = df_.shape[0]\n",
    "    result_array = []\n",
    "    for i in range(N):\n",
    "        rand_user = random.choice(users_list)\n",
    "        rand_item = random.choice(item_list)\n",
    "        rand_context = random.choice(context_list)\n",
    "        fake_feedback = 0\n",
    "        random_gen = (rand_user, rand_item, rand_context, fake_feedback)\n",
    "        result_array.append(random_gen)\n",
    "    \n",
    "    if all_users: \n",
    "        for user in users_list:\n",
    "            rand_item = random.choice(item_list)\n",
    "            rand_context = random.choice(context_list)\n",
    "            fake_feedback = 0\n",
    "            random_gen = (user, rand_item, rand_context, fake_feedback)\n",
    "            result_array.append(random_gen)\n",
    "            \n",
    "    if all_items:\n",
    "        for item in item_list:\n",
    "            rand_user = random.choice(users_list)\n",
    "            rand_context = random.choice(context_list)\n",
    "            fake_feedback = 0\n",
    "            random_gen = (rand_user, item, rand_context, fake_feedback)\n",
    "            result_array.append(random_gen)\n",
    "    \n",
    "    zero_df = pd.DataFrame(result_array, columns=['user_id', 'item_id', 'context_feature_id', 'feedback'])\n",
    "    \n",
    "    df_with_zeros = pd.concat([df_, zero_df])\n",
    "    df_with_zeros = df_with_zeros.drop_duplicates(subset=['user_id', 'item_id'], keep='first')\n",
    "    return df_with_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "814de277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique users items and context\n",
    "users = np.sort(data.user_id.unique())\n",
    "unique_items = np.sort(data.item_id.unique())\n",
    "context = np.sort(data.context_feature_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "313a8399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call zero sampling to get dataframe with zeros\n",
    "df = zero_sampling(data, users, unique_items, context, all_users=True, all_items=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555e7aae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99a4086e",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00b16607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "np.random.seed(0)\n",
    "mask = np.random.rand(len(df)) < 0.8\n",
    "train = df[mask].reset_index()\n",
    "valid = df[~mask].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc8a703",
   "metadata": {},
   "source": [
    "# Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b7c761c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, emb_size=100, seed=23):\n",
    "        super(MF, self).__init__()\n",
    "        torch.manual_seed(seed)\n",
    "        self.user_emb = nn.Embedding(num_users, emb_size)\n",
    "        self.user_bias = nn.Embedding(num_users, 1)\n",
    "        self.item_emb = nn.Embedding(num_items, emb_size)\n",
    "        self.item_bias = nn.Embedding(num_items, 1)\n",
    "        # init \n",
    "        self.user_emb.weight.data.uniform_(-0.05,0.05)\n",
    "        self.item_emb.weight.data.uniform_(-0.05,0.05)\n",
    "        self.user_bias.weight.data.uniform_(-0.01,0.01)\n",
    "        self.item_bias.weight.data.uniform_(-0.01,0.01)\n",
    "\n",
    "    def forward(self, u, v):\n",
    "        U = self.user_emb(u)\n",
    "        V = self.item_emb(v)\n",
    "        b_i = self.user_bias(u).squeeze()\n",
    "        c_j = self.item_bias(v).squeeze()\n",
    "        \n",
    "        return torch.sigmoid((U * V).sum(1) + b_i + c_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e6202da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169707 37988\n"
     ]
    }
   ],
   "source": [
    "num_users = len(train.user_id.unique()) + 10\n",
    "num_items = len(train.item_id.unique()) + 10\n",
    "print(num_users, num_items) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "481f311e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def change_id(df_, col, random_choices):\n",
    "#     \"\"\"This function will randomly assign user_id or item_id\n",
    "#     if the id = -1'\"\"\"\n",
    "# #     random_ = np.arange(1, len(random_choices)-1)\n",
    "#     for index, row in df_.iterrows():\n",
    "#         if row[col] == -1:\n",
    "#             rand = np.random.choice(random_choices)\n",
    "#             df_.at[index, col] = rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f93c6c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the user_id\n",
    "train_user_ids = np.sort(np.unique(train.user_id.values))\n",
    "userid2idx = {o:i for i,o in enumerate(train_user_ids)}\n",
    "\n",
    "# map the encoding\n",
    "train[\"user_id\"] = train[\"user_id\"].apply(lambda x: userid2idx[x])\n",
    "valid[\"user_id\"] = valid[\"user_id\"].apply(lambda x: userid2idx.get(x, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dafe65ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the item_id\n",
    "train_item_ids = np.sort(np.unique(train.item_id.values))\n",
    "itemid2idx = {o:i for i,o in enumerate(train_item_ids)}\n",
    "\n",
    "# map the encoding\n",
    "train[\"item_id\"] = train[\"item_id\"].apply(lambda x: itemid2idx[x])\n",
    "valid[\"item_id\"] = valid[\"item_id\"].apply(lambda x: itemid2idx.get(x, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b03e692",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_ids = np.sort(np.unique(train.user_id.values))\n",
    "new_item_ids = np.sort(np.unique(train.item_id.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb8f6134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_id_to_max(df_, col, max_choice):\n",
    "    \"\"\"This function will assign user_id or item_id\n",
    "    if the id = -1 to the max'\"\"\"\n",
    "#     random_ = np.arange(1, len(random_choices)-1)\n",
    "    for index, row in df_.iterrows():\n",
    "        if row[col] == -1:\n",
    "            df_.at[index, col] = max_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20eec311",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_userid = train.user_id.values.max() + 1\n",
    "max_itemid = train.item_id.values.max() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82d00b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly assign the cold starts to something seen in the training\n",
    "change_id_to_max(valid, 'user_id', max_userid)\n",
    "change_id_to_max(valid, 'item_id', max_itemid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1497fa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_loss(model):\n",
    "    model.eval()\n",
    "    users = torch.LongTensor(valid.user_id.values) \n",
    "    items = torch.LongTensor(valid.item_id.values) \n",
    "    feedback = torch.FloatTensor(valid.feedback.values) \n",
    "    y_hat = model(users, items)\n",
    "    loss = F.binary_cross_entropy(y_hat, feedback)\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c350b1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are not using data loaders because our data fits well in memory\n",
    "def train_epocs(model, epochs=10, lr=0.01, wd=0.0):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        users = torch.LongTensor(train.user_id.values)  \n",
    "        items = torch.LongTensor(train.item_id.values) \n",
    "        feedback = torch.FloatTensor(train.feedback.values)  \n",
    "    \n",
    "        y_hat = model(users, items)\n",
    "        \n",
    "        loss = F.binary_cross_entropy(y_hat, feedback)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        testloss = valid_loss(model)\n",
    "        print('Epoch Number:', i+1,\"train loss %.3f valid loss %.3f\" % (loss.item(), testloss)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b10edf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MF(num_users, num_items, emb_size=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f96fa50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number: 1 train loss 0.693 valid loss 0.656\n",
      "Epoch Number: 2 train loss 0.614 valid loss 0.609\n",
      "Epoch Number: 3 train loss 0.429 valid loss 0.557\n",
      "Epoch Number: 4 train loss 0.231 valid loss 0.513\n",
      "Epoch Number: 5 train loss 0.090 valid loss 0.496\n",
      "Epoch Number: 6 train loss 0.027 valid loss 0.503\n",
      "Epoch Number: 7 train loss 0.008 valid loss 0.520\n",
      "Epoch Number: 8 train loss 0.002 valid loss 0.533\n",
      "Epoch Number: 9 train loss 0.001 valid loss 0.538\n",
      "Epoch Number: 10 train loss 0.001 valid loss 0.534\n",
      "Epoch Number: 11 train loss 0.000 valid loss 0.522\n",
      "Epoch Number: 12 train loss 0.000 valid loss 0.504\n",
      "Epoch Number: 13 train loss 0.001 valid loss 0.482\n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, epochs=13, lr=0.1, wd = 0.0000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5689ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number: 1 train loss 0.001 valid loss 0.451\n",
      "Epoch Number: 2 train loss 0.002 valid loss 0.429\n",
      "Epoch Number: 3 train loss 0.005 valid loss 0.412\n",
      "Epoch Number: 4 train loss 0.009 valid loss 0.399\n",
      "Epoch Number: 5 train loss 0.016 valid loss 0.388\n",
      "Epoch Number: 6 train loss 0.025 valid loss 0.378\n",
      "Epoch Number: 7 train loss 0.032 valid loss 0.368\n",
      "Epoch Number: 8 train loss 0.036 valid loss 0.357\n",
      "Epoch Number: 9 train loss 0.036 valid loss 0.345\n",
      "Epoch Number: 10 train loss 0.033 valid loss 0.334\n",
      "Epoch Number: 11 train loss 0.028 valid loss 0.323\n",
      "Epoch Number: 12 train loss 0.023 valid loss 0.314\n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, epochs=12, lr=0.05, wd = 0.0000001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b2d582",
   "metadata": {},
   "source": [
    "- 5 epochs and the 10 epochs for final model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448737b7",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1816e7ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>context_feature_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>16835</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>22590</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1978</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>28916</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>14427</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  user_id  item_id  context_feature_id\n",
       "0   0        4    16835                   2\n",
       "1   1        4    22590                   3\n",
       "2   2        4     1978                   1\n",
       "3   3        4    28916                   1\n",
       "4   4        4    14427                   2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = df.copy()\n",
    "test = pd.read_csv('test_kaggle.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c00178b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169708 37988\n"
     ]
    }
   ],
   "source": [
    "num_users = len(train.user_id.unique()) + 10\n",
    "num_items = len(train.item_id.unique()) + 10\n",
    "print(num_users, num_items) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c80aacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the user_id\n",
    "train_user_ids = np.sort(np.unique(train.user_id.values))\n",
    "userid2idx = {o:i for i,o in enumerate(train_user_ids)}\n",
    "\n",
    "# map the encoding\n",
    "train[\"user_id\"] = train[\"user_id\"].apply(lambda x: userid2idx[x])\n",
    "test[\"user_id\"] = test[\"user_id\"].apply(lambda x: userid2idx.get(x, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "456c06f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the item_id\n",
    "train_item_ids = np.sort(np.unique(train.item_id.values))\n",
    "itemid2idx = {o:i for i,o in enumerate(train_item_ids)}\n",
    "\n",
    "# map the encoding\n",
    "train[\"item_id\"] = train[\"item_id\"].apply(lambda x: itemid2idx[x])\n",
    "test[\"item_id\"] = test[\"item_id\"].apply(lambda x: itemid2idx.get(x, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "060ba9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_userid = train.user_id.values.max() + 1\n",
    "max_itemid = train.item_id.values.max() + 1\n",
    "\n",
    "# randomly assign the cold starts to something seen in the training\n",
    "change_id_to_max(test, 'user_id', max_userid)\n",
    "change_id_to_max(test, 'item_id', max_itemid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0eb85aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MF(num_users, num_items, emb_size=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba86514c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number: 1 train loss 0.693 valid loss 0.655\n",
      "Epoch Number: 2 train loss 0.654 valid loss 0.613\n",
      "Epoch Number: 3 train loss 0.549 valid loss 0.570\n",
      "Epoch Number: 4 train loss 0.436 valid loss 0.526\n",
      "Epoch Number: 5 train loss 0.314 valid loss 0.485\n",
      "Epoch Number: 6 train loss 0.213 valid loss 0.451\n",
      "Epoch Number: 7 train loss 0.149 valid loss 0.427\n",
      "Epoch Number: 8 train loss 0.121 valid loss 0.412\n",
      "Epoch Number: 9 train loss 0.118 valid loss 0.401\n",
      "Epoch Number: 10 train loss 0.126 valid loss 0.393\n",
      "Epoch Number: 11 train loss 0.134 valid loss 0.388\n",
      "Epoch Number: 12 train loss 0.139 valid loss 0.385\n",
      "Epoch Number: 13 train loss 0.141 valid loss 0.385\n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, epochs=13, lr=0.1, wd = 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "12e6d2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number: 1 train loss 0.144 valid loss 0.381\n",
      "Epoch Number: 2 train loss 0.155 valid loss 0.378\n",
      "Epoch Number: 3 train loss 0.154 valid loss 0.377\n",
      "Epoch Number: 4 train loss 0.156 valid loss 0.375\n",
      "Epoch Number: 5 train loss 0.158 valid loss 0.373\n",
      "Epoch Number: 6 train loss 0.160 valid loss 0.371\n",
      "Epoch Number: 7 train loss 0.160 valid loss 0.369\n",
      "Epoch Number: 8 train loss 0.158 valid loss 0.366\n",
      "Epoch Number: 9 train loss 0.154 valid loss 0.364\n",
      "Epoch Number: 10 train loss 0.152 valid loss 0.362\n",
      "Epoch Number: 11 train loss 0.150 valid loss 0.360\n",
      "Epoch Number: 12 train loss 0.149 valid loss 0.359\n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, epochs=12, lr=0.05, wd = 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ecee22b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predictions\n",
    "test_users = torch.LongTensor(test.user_id.values)\n",
    "test_items = torch.LongTensor(test.item_id.values)\n",
    "y_hat = model(test_users, test_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48c5d531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detach to numpy\n",
    "y_hat = y_hat.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ea4ba433",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['rating'] = y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "402c135b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = test['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "711f66ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.to_csv('weight_decay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf7ff2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
